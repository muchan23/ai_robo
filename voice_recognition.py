#!/usr/bin/env python3
"""
ãƒ©ã‚ºãƒ‘ã‚¤éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ 
ãƒã‚¤ã‚¯éŸ³å£°å…¥åŠ›ã‹ã‚‰éŸ³å£°èªè­˜ã¾ã§
"""

import os
import sys
import time
import logging
import pyaudio
import numpy as np
import tempfile
import wave
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

class VoiceRecognition:
    """éŸ³å£°èªè­˜ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.logger = self._setup_logging()
        
        # OpenAI APIè¨­å®š
        self.api_key = os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        self.client = OpenAI(api_key=self.api_key)
        
        # éŸ³å£°è¨­å®š
        self.sample_rate = int(os.getenv('SAMPLE_RATE', '16000'))
        self.chunk_size = int(os.getenv('CHUNK_SIZE', '1024'))
        self.audio_threshold = int(os.getenv('AUDIO_THRESHOLD', '1000'))
        
        # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ 
        self.audio = pyaudio.PyAudio()
        self.stream = None
        self.is_recording = False
        
        self.logger.info("éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    
    def _setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        log_level = os.getenv('LOG_LEVEL', 'INFO')
        logging.basicConfig(
            level=getattr(logging, log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)
    
    def start_recording(self, duration=5):
        """
        éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹
        
        Args:
            duration: éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
        """
        self.logger.info(f"éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆ{duration}ç§’é–“ï¼‰")
        
        try:
            # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ã
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
            frames = []
            for _ in range(0, int(self.sample_rate / self.chunk_size * duration)):
                data = self.stream.read(self.chunk_size)
                frames.append(data)
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‰ã˜ã‚‹
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
            audio_data = b''.join(frames)
            
            self.logger.info("éŸ³å£°éŒ²éŸ³ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return audio_data
            
        except Exception as e:
            self.logger.error(f"éŸ³å£°éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()
            raise
    
    def detect_speech(self, duration=3):
        """
        éŸ³å£°æ¤œå‡ºéŒ²éŸ³ï¼ˆéŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã‚‹ã¾ã§éŒ²éŸ³ï¼‰
        
        Args:
            duration: æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
        """
        self.logger.info("éŸ³å£°æ¤œå‡ºéŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™")
        
        try:
            # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ã
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )
            
            frames = []
            silent_frames = 0
            max_silent_frames = int(self.sample_rate / self.chunk_size * 2)  # 2ç§’é–“ã®ç„¡éŸ³
            max_frames = int(self.sample_rate / self.chunk_size * duration)
            
            for i in range(max_frames):
                data = self.stream.read(self.chunk_size)
                frames.append(data)
                
                # éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                audio_array = np.frombuffer(data, dtype=np.int16)
                max_amplitude = np.max(np.abs(audio_array))
                
                if max_amplitude > self.audio_threshold:
                    silent_frames = 0
                    self.logger.debug(f"éŸ³å£°æ¤œå‡º: ãƒ¬ãƒ™ãƒ«={max_amplitude}")
                else:
                    silent_frames += 1
                
                # ç„¡éŸ³ãŒç¶šã„ãŸã‚‰éŒ²éŸ³çµ‚äº†
                if silent_frames > max_silent_frames and len(frames) > int(self.sample_rate / self.chunk_size * 1):
                    self.logger.info("ç„¡éŸ³æ¤œå‡ºã«ã‚ˆã‚ŠéŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã™")
                    break
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‰ã˜ã‚‹
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
            audio_data = b''.join(frames)
            
            self.logger.info(f"éŸ³å£°æ¤œå‡ºéŒ²éŸ³ãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆ{len(frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰")
            return audio_data
            
        except Exception as e:
            self.logger.error(f"éŸ³å£°æ¤œå‡ºéŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()
            raise
    
    def transcribe_audio(self, audio_data):
        """
        éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—èµ·ã“ã—
        
        Args:
            audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¤ãƒˆï¼‰
            
        Returns:
            æ–‡å­—èµ·ã“ã—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        self.logger.info("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­...")
        
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                with wave.open(temp_file.name, 'wb') as wav_file:
                    wav_file.setnchannels(1)
                    wav_file.setsampwidth(2)  # 16bit
                    wav_file.setframerate(self.sample_rate)
                    wav_file.writeframes(audio_data)
                
                # OpenAI Whisper APIã§æ–‡å­—èµ·ã“ã—
                with open(temp_file.name, 'rb') as audio_file:
                    transcript = self.client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="ja"
                    )
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                os.unlink(temp_file.name)
                
                result = transcript.text.strip()
                self.logger.info(f"æ–‡å­—èµ·ã“ã—å®Œäº†: {result}")
                return result
                
        except Exception as e:
            self.logger.error(f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        self.audio.terminate()
        self.logger.info("ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ¤ ãƒ©ã‚ºãƒ‘ã‚¤éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)
    
    try:
        # éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        voice_recognition = VoiceRecognition()
        
        print("ğŸ¯ éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™")
        print("ğŸ’¡ è©±ã—ã‹ã‘ã¦ãã ã•ã„...")
        print("â¹ï¸  Ctrl+C ã§çµ‚äº†")
        
        while True:
            try:
                # éŸ³å£°æ¤œå‡ºéŒ²éŸ³
                print("\nğŸ¤ éŸ³å£°ã‚’æ¤œå‡ºä¸­...")
                audio_data = voice_recognition.detect_speech(duration=10)
                
                if len(audio_data) > 0:
                    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                    result = voice_recognition.transcribe_audio(audio_data)
                    
                    if result:
                        print(f"ğŸ“ èªè­˜çµæœ: {result}")
                    else:
                        print("âŒ éŸ³å£°ãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                else:
                    print("âŒ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                    
            except KeyboardInterrupt:
                print("\nğŸ›‘ çµ‚äº†ã—ã¾ã™...")
                break
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    finally:
        if 'voice_recognition' in locals():
            voice_recognition.cleanup()
    
    return 0


if __name__ == "__main__":
    exit(main())
