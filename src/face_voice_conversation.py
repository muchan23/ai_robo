#!/usr/bin/env python3
"""
é¡”è¡¨æƒ…ä»˜ãéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ 
éŸ³å£°ä¼šè©±ã¨è¡¨æƒ…è¡¨ç¤ºã‚’çµ±åˆã—ãŸã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import logging
import time
import threading
import pygame
from typing import Optional, Callable
from pathlib import Path

from voice_conversation import VoiceConversation
from face_display import FaceDisplay, Emotion


class FaceVoiceConversation:
    """é¡”è¡¨æƒ…ä»˜ãéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 api_key: Optional[str] = None,
                 chat_model: str = "gpt-4o-mini",
                 tts_voice: str = "alloy",
                 tts_model: str = "tts-1",
                 whisper_model: str = "whisper-1",
                 system_prompt: Optional[str] = None,
                 screen_width: int = 800,
                 screen_height: int = 600,
                 fullscreen: bool = False):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key: OpenAI APIã‚­ãƒ¼
            chat_model: ChatGPTãƒ¢ãƒ‡ãƒ«
            tts_voice: TTSéŸ³å£°ã®ç¨®é¡
            tts_model: TTSãƒ¢ãƒ‡ãƒ«
            whisper_model: Whisperãƒ¢ãƒ‡ãƒ«
            system_prompt: AIã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            screen_width: ç”»é¢å¹…
            screen_height: ç”»é¢é«˜ã•
            fullscreen: ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒ¢ãƒ¼ãƒ‰
        """
        self.logger = logging.getLogger(__name__)
        
        # éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        self.voice_conversation = VoiceConversation(
            api_key=api_key,
            chat_model=chat_model,
            tts_voice=tts_voice,
            tts_model=tts_model,
            whisper_model=whisper_model,
            system_prompt=system_prompt
        )
        
        # é¡”è¡¨æƒ…è¡¨ç¤ºã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        self.face_display = FaceDisplay(
            screen_width=screen_width,
            screen_height=screen_height,
            fullscreen=fullscreen
        )
        
        # çŠ¶æ…‹ç®¡ç†
        self.is_running = False
        self.face_thread = None
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’è¨­å®š
        self.voice_conversation.on_user_speech = self._on_user_speech
        self.voice_conversation.on_ai_response = self._on_ai_response
        self.voice_conversation.on_error = self._on_error
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        self.on_user_speech: Optional[Callable[[str], None]] = None
        self.on_ai_response: Optional[Callable[[str], None]] = None
        self.on_error: Optional[Callable[[Exception], None]] = None
        
        self.logger.info("é¡”è¡¨æƒ…ä»˜ãéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    
    def start_conversation(self, 
                          auto_mode: bool = True,
                          max_duration: float = 30.0,
                          silence_threshold: float = 0.01,
                          silence_duration: float = 2.0):
        """
        éŸ³å£°ä¼šè©±ã‚’é–‹å§‹ã™ã‚‹
        
        Args:
            auto_mode: è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹
            max_duration: æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
            silence_threshold: ç„¡éŸ³åˆ¤å®šã®é–¾å€¤
            silence_duration: ç„¡éŸ³ç¶™ç¶šæ™‚é–“ï¼ˆç§’ï¼‰
        """
        if self.is_running:
            self.logger.warning("æ—¢ã«ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ãŒå‹•ä½œä¸­ã§ã™")
            return
        
        self.is_running = True
        
        # é¡”è¡¨æƒ…è¡¨ç¤ºã‚’é–‹å§‹
        self.face_thread = threading.Thread(target=self._face_display_loop)
        self.face_thread.daemon = True
        self.face_thread.start()
        
        # éŸ³å£°ä¼šè©±ã‚’é–‹å§‹
        self.voice_conversation.start_conversation(
            auto_mode=auto_mode,
            max_duration=max_duration,
            silence_threshold=silence_threshold,
            silence_duration=silence_duration
        )
        
        self.logger.info("é¡”è¡¨æƒ…ä»˜ãéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
    
    def stop_conversation(self):
        """éŸ³å£°ä¼šè©±ã‚’åœæ­¢ã™ã‚‹"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        # éŸ³å£°ä¼šè©±ã‚’åœæ­¢
        self.voice_conversation.stop_conversation()
        
        # é¡”è¡¨æƒ…è¡¨ç¤ºã‚’åœæ­¢
        if self.face_thread:
            self.face_thread.join()
        
        self.logger.info("é¡”è¡¨æƒ…ä»˜ãéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    def _face_display_loop(self):
        """é¡”è¡¨æƒ…è¡¨ç¤ºã®ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        try:
            # åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
            self.face_display.set_emotion(Emotion.NEUTRAL, animate=False)
            
            # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
            clock = pygame.time.Clock()
            
            while self.is_running:
                # ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
                for event in pygame.event.get():
                    if event.type == pygame.QUIT:
                        self.is_running = False
                    elif event.type == pygame.KEYDOWN:
                        if event.key == pygame.K_ESCAPE:
                            self.is_running = False
                
                # é¡”ã‚’æç”»
                self.face_display.draw_face()
                
                # FPSåˆ¶é™
                clock.tick(60)
                
        except Exception as e:
            self.logger.error(f"é¡”è¡¨æƒ…è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            pygame.quit()
    
    def _on_user_speech(self, text: str):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°èªè­˜çµæœã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€: {text}")
        
        # è¡¨æƒ…ã‚’ã€Œèã„ã¦ã„ã‚‹ã€çŠ¶æ…‹ã«å¤‰æ›´
        self.face_display.set_emotion(Emotion.LISTENING)
        
        # å¤–éƒ¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        if self.on_user_speech:
            self.on_user_speech(text)
    
    def _on_ai_response(self, text: str):
        """AIå¿œç­”ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.logger.info(f"AIå¿œç­”: {text}")
        
        # å¿œç­”å†…å®¹ã«åŸºã¥ã„ã¦è¡¨æƒ…ã‚’æ±ºå®š
        emotion = self._analyze_emotion_from_text(text)
        self.face_display.set_emotion(emotion)
        
        # å¤–éƒ¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        if self.on_ai_response:
            self.on_ai_response(text)
    
    def _on_error(self, error: Exception):
        """ã‚¨ãƒ©ãƒ¼ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {error}")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æ‚²ã—ã„è¡¨æƒ…
        self.face_display.set_emotion(Emotion.SAD)
        
        # å¤–éƒ¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        if self.on_error:
            self.on_error(error)
    
    def _analyze_emotion_from_text(self, text: str) -> Emotion:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†æã™ã‚‹
        
        Args:
            text: åˆ†æã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            åˆ†æã•ã‚ŒãŸæ„Ÿæƒ…
        """
        text_lower = text.lower()
        
        # å–œã³ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        happy_keywords = ['ã‚ã‚ŠãŒã¨ã†', 'å¬‰ã—ã„', 'æ¥½ã—ã„', 'é¢ç™½ã„', 'ç´ æ™´ã‚‰ã—ã„', 'æœ€é«˜', 'ã„ã„', 'è‰¯ã„']
        if any(keyword in text_lower for keyword in happy_keywords):
            return Emotion.HAPPY
        
        # æ‚²ã—ã¿ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        sad_keywords = ['æ‚²ã—ã„', 'æ®‹å¿µ', 'ç”³ã—è¨³ãªã„', 'ã”ã‚ã‚“', 'ã™ã¿ã¾ã›ã‚“', 'å›°ã£ãŸ', 'å¤§å¤‰']
        if any(keyword in text_lower for keyword in sad_keywords):
            return Emotion.SAD
        
        # é©šãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        surprised_keywords = ['é©šã„ãŸ', 'ã³ã£ãã‚Š', 'ã™ã”ã„', 'æœ¬å½“', 'ã¾ã•ã‹', 'ä¿¡ã˜ã‚‰ã‚Œãªã„']
        if any(keyword in text_lower for keyword in surprised_keywords):
            return Emotion.SURPRISED
        
        # æ€’ã‚Šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        angry_keywords = ['æ€’ã‚‹', 'è…¹ç«‹ã¤', 'ã‚¤ãƒ©ã‚¤ãƒ©', 'ã†ã‚‹ã•ã„', 'ã‚„ã‚ã¦', 'ã ã‚']
        if any(keyword in text_lower for keyword in angry_keywords):
            return Emotion.ANGRY
        
        # æ€è€ƒã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        thinking_keywords = ['è€ƒãˆ', 'æ€ã†', 'ã©ã†', 'ãªãœ', 'ãªã‚“ã§', 'ç†ç”±', 'åŸå› ']
        if any(keyword in text_lower for keyword in thinking_keywords):
            return Emotion.THINKING
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä¸­æ€§
        return Emotion.NEUTRAL
    
    def set_emotion(self, emotion: Emotion, animate: bool = True):
        """
        è¡¨æƒ…ã‚’æ‰‹å‹•ã§è¨­å®šã™ã‚‹
        
        Args:
            emotion: è¨­å®šã™ã‚‹æ„Ÿæƒ…
            animate: ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã‹ã©ã†ã‹
        """
        self.face_display.set_emotion(emotion, animate)
    
    def process_audio_file(self, audio_file_path: str) -> str:
        """
        æŒ‡å®šã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦AIå¿œç­”ã‚’è¿”ã™
        
        Args:
            audio_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            AIå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # èã„ã¦ã„ã‚‹è¡¨æƒ…ã«å¤‰æ›´
        self.face_display.set_emotion(Emotion.LISTENING)
        
        # éŸ³å£°å‡¦ç†
        response = self.voice_conversation.process_audio_file(audio_file_path)
        
        # å¿œç­”å†…å®¹ã«åŸºã¥ã„ã¦è¡¨æƒ…ã‚’å¤‰æ›´
        emotion = self._analyze_emotion_from_text(response)
        self.face_display.set_emotion(emotion)
        
        return response
    
    def speak_response(self, text: str):
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã§å†ç”Ÿã™ã‚‹
        
        Args:
            text: å†ç”Ÿã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # è©±ã—ã¦ã„ã‚‹è¡¨æƒ…ã«å¤‰æ›´
        self.face_display.set_emotion(Emotion.SPEAKING)
        
        # éŸ³å£°å†ç”Ÿ
        self.voice_conversation.speak_response(text)
        
        # å†ç”Ÿå®Œäº†å¾Œã¯ä¸­æ€§ã«æˆ»ã™
        time.sleep(0.5)  # å°‘ã—å¾…æ©Ÿ
        self.face_display.set_emotion(Emotion.NEUTRAL)
    
    def reset_conversation(self):
        """ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹"""
        self.voice_conversation.reset_conversation()
        self.face_display.set_emotion(Emotion.NEUTRAL)
        self.logger.info("ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
    
    def set_system_prompt(self, prompt: str):
        """
        ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´ã™ã‚‹
        
        Args:
            prompt: æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        self.voice_conversation.set_system_prompt(prompt)
        self.logger.info("ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´ã—ã¾ã—ãŸ")
    
    def set_tts_voice(self, voice: str):
        """
        TTSéŸ³å£°ã‚’å¤‰æ›´ã™ã‚‹
        
        Args:
            voice: æ–°ã—ã„éŸ³å£°ã®ç¨®é¡
        """
        self.voice_conversation.set_tts_voice(voice)
        self.logger.info(f"TTSéŸ³å£°ã‚’å¤‰æ›´ã—ã¾ã—ãŸ: {voice}")


def main():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    parser = argparse.ArgumentParser(description='é¡”è¡¨æƒ…ä»˜ãéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--auto', action='store_true', help='è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--audio-file', help='å‡¦ç†ã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--voice', default='alloy', help='TTSéŸ³å£°ã®ç¨®é¡')
    parser.add_argument('--fullscreen', action='store_true', help='ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--width', type=int, default=800, help='ç”»é¢å¹…')
    parser.add_argument('--height', type=int, default=600, help='ç”»é¢é«˜ã•')
    
    args = parser.parse_args()
    
    try:
        # é¡”è¡¨æƒ…ä»˜ãéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆ
        conversation = FaceVoiceConversation(
            tts_voice=args.voice,
            screen_width=args.width,
            screen_height=args.height,
            fullscreen=args.fullscreen
        )
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’è¨­å®š
        def on_user_speech(text):
            print(f"ğŸ¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {text}")
        
        def on_ai_response(text):
            print(f"ğŸ¤– AI: {text}")
        
        def on_error(error):
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {error}")
        
        conversation.on_user_speech = on_user_speech
        conversation.on_ai_response = on_ai_response
        conversation.on_error = on_error
        
        if args.audio_file:
            # å˜ç™ºã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
            print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­: {args.audio_file}")
            response = conversation.process_audio_file(args.audio_file)
            print(f"AIå¿œç­”: {response}")
            conversation.speak_response(response)
        
        elif args.auto:
            # è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
            print("é¡”è¡¨æƒ…ä»˜ãè‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚Ctrl+Cã§çµ‚äº†...")
            conversation.start_conversation(auto_mode=True)
            
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                conversation.stop_conversation()
        
        else:
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  --auto: é¡”è¡¨æƒ…ä»˜ãè‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰")
            print("  --audio-file <path>: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
            print("  --fullscreen: ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ãƒ¢ãƒ¼ãƒ‰")
    
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
