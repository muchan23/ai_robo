#!/usr/bin/env python3
"""
é«˜é€ŸéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ 
ä¸¦åˆ—å‡¦ç†ã¨æœ€é©åŒ–ã«ã‚ˆã‚Šå¿œç­”æ™‚é–“ã‚’å¤§å¹…çŸ­ç¸®
"""

import os
import logging
import time
import threading
import asyncio
import concurrent.futures
from typing import Optional, Callable
from pathlib import Path

from speech_to_text import SpeechToText
from ai_chat import AIChat
from text_to_speech import TextToSpeech
from audio_recorder import AudioRecorder
from config import get_config


class FastVoiceConversation:
    """é«˜é€ŸéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 api_key: Optional[str] = None,
                 chat_model: str = "gpt-4o-mini",
                 tts_voice: str = "alloy",
                 tts_model: str = "tts-1",
                 whisper_model: str = "whisper-1",
                 system_prompt: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key: OpenAI APIã‚­ãƒ¼
            chat_model: ChatGPTãƒ¢ãƒ‡ãƒ«
            tts_voice: TTSéŸ³å£°ã®ç¨®é¡
            tts_model: TTSãƒ¢ãƒ‡ãƒ«
            whisper_model: Whisperãƒ¢ãƒ‡ãƒ«
            system_prompt: AIã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.logger = logging.getLogger(__name__)
        
        # å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
        self.speech_to_text = SpeechToText(api_key=self.api_key)
        self.ai_chat = AIChat(
            api_key=self.api_key,
            model=chat_model,
            system_prompt=system_prompt
        )
        self.text_to_speech = TextToSpeech(
            api_key=self.api_key,
            voice=tts_voice,
            model=tts_model
        )
        
        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        config = get_config()
        self.audio_recorder = AudioRecorder(
            sample_rate=config.sample_rate,
            chunk_size=config.chunk_size
        )
        
        # çŠ¶æ…‹ç®¡ç†
        self.is_running = False
        self.conversation_thread = None
        self.recording_dir = Path("recordings")
        self.recording_dir.mkdir(exist_ok=True)
        
        # ä¸¦åˆ—å‡¦ç†ç”¨ã®ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=3)
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        self.on_user_speech: Optional[Callable[[str], None]] = None
        self.on_ai_response: Optional[Callable[[str], None]] = None
        self.on_error: Optional[Callable[[Exception], None]] = None
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆæ¸¬
        self.performance_stats = {
            'total_requests': 0,
            'total_time': 0,
            'avg_response_time': 0
        }
    
    def start_conversation(self, 
                          auto_mode: bool = True,
                          max_duration: float = 30.0,
                          silence_threshold: float = 0.01,
                          silence_duration: float = 2.0):
        """
        éŸ³å£°ä¼šè©±ã‚’é–‹å§‹ã™ã‚‹
        
        Args:
            auto_mode: è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹
            max_duration: æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
            silence_threshold: ç„¡éŸ³åˆ¤å®šã®é–¾å€¤
            silence_duration: ç„¡éŸ³ç¶™ç¶šæ™‚é–“ï¼ˆç§’ï¼‰
        """
        if self.is_running:
            self.logger.warning("æ—¢ã«ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ãŒå‹•ä½œä¸­ã§ã™")
            return
        
        self.is_running = True
        
        if auto_mode:
            # è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
            self.logger.info("é«˜é€Ÿè‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã§ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™")
            self.audio_recorder.start_continuous_recording(
                output_dir=str(self.recording_dir),
                max_duration=max_duration,
                silence_threshold=silence_threshold,
                silence_duration=silence_duration,
                callback=self._process_audio_file_fast
            )
        else:
            # æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã§å¾…æ©Ÿï¼‰
            self.conversation_thread = threading.Thread(
                target=self._manual_conversation_loop
            )
            self.conversation_thread.start()
            self.logger.info("é«˜é€Ÿæ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã§ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™")
    
    def stop_conversation(self):
        """éŸ³å£°ä¼šè©±ã‚’åœæ­¢ã™ã‚‹"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        # éŒ²éŸ³ã‚’åœæ­¢
        self.audio_recorder.stop_continuous_recording()
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿ
        if self.conversation_thread:
            self.conversation_thread.join()
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã‚’ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
        self.executor.shutdown(wait=True)
        
        self.logger.info("é«˜é€Ÿä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    def _process_audio_file_fast(self, audio_file_path: str):
        """
        éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é«˜é€Ÿå‡¦ç†ã™ã‚‹ï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰
        
        Args:
            audio_file_path: éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        start_time = time.time()
        
        try:
            self.logger.info(f"é«˜é€ŸéŸ³å£°å‡¦ç†é–‹å§‹: {audio_file_path}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: éŸ³å£°èªè­˜ï¼ˆä¸¦åˆ—å‡¦ç†ã®æº–å‚™ï¼‰
            def transcribe_audio():
                return self.speech_to_text.transcribe_audio_file(
                    audio_file_path=audio_file_path,
                    language="ja",
                    response_format="text"
                )
            
            # éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œ
            user_text = transcribe_audio()
            
            if not user_text.strip():
                self.logger.info("éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return
            
            self.logger.info(f"èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {user_text}")
            
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            if self.on_user_speech:
                self.on_user_speech(user_text)
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: AIå¿œç­”ç”Ÿæˆï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
            def generate_ai_response():
                return self.ai_chat.chat(
                    user_text,
                    max_tokens=80,  # ã‚ˆã‚ŠçŸ­ã„å¿œç­”
                    temperature=0.7
                )
            
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = generate_ai_response()
            
            self.logger.info(f"AIå¿œç­”: {ai_response}")
            
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            if self.on_ai_response:
                self.on_ai_response(ai_response)
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: éŸ³å£°åˆæˆã¨å†ç”Ÿï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
            def synthesize_and_play():
                # éŸ³å£°åˆæˆ
                audio_path = self.text_to_speech.speak_text(
                    ai_response,
                    play_audio=True
                )
                return audio_path
            
            # éŸ³å£°åˆæˆã‚’ä¸¦åˆ—å®Ÿè¡Œ
            future = self.executor.submit(synthesize_and_play)
            
            # éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ï¼‰
            try:
                Path(audio_file_path).unlink()
                self.logger.debug(f"éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {audio_file_path}")
            except Exception as e:
                self.logger.warning(f"éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {e}")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’æ›´æ–°
            end_time = time.time()
            response_time = end_time - start_time
            
            self.performance_stats['total_requests'] += 1
            self.performance_stats['total_time'] += response_time
            self.performance_stats['avg_response_time'] = (
                self.performance_stats['total_time'] / self.performance_stats['total_requests']
            )
            
            self.logger.info(f"é«˜é€Ÿå‡¦ç†å®Œäº†: {response_time:.2f}ç§’")
            
        except Exception as e:
            self.logger.error(f"é«˜é€ŸéŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            if self.on_error:
                self.on_error(e)
    
    def _manual_conversation_loop(self):
        """æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã®ä¼šè©±ãƒ«ãƒ¼ãƒ—"""
        self.logger.info("é«˜é€Ÿæ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        while self.is_running:
            try:
                time.sleep(1)  # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            except Exception as e:
                self.logger.error(f"é«˜é€Ÿæ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                if self.on_error:
                    self.on_error(e)
                break
    
    def process_audio_file_fast(self, audio_file_path: str) -> str:
        """
        æŒ‡å®šã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é«˜é€Ÿå‡¦ç†ã—ã¦AIå¿œç­”ã‚’è¿”ã™
        
        Args:
            audio_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            AIå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆ
        """
        start_time = time.time()
        
        try:
            # éŸ³å£°èªè­˜
            user_text = self.speech_to_text.transcribe_audio_file(
                audio_file_path=audio_file_path,
                language="ja"
            )
            
            if not user_text.strip():
                return "éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = self.ai_chat.chat(user_text, max_tokens=80)
            
            end_time = time.time()
            self.logger.info(f"é«˜é€Ÿå‡¦ç†æ™‚é–“: {end_time - start_time:.2f}ç§’")
            
            return ai_response
            
        except Exception as e:
            self.logger.error(f"é«˜é€ŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    
    def speak_response_fast(self, text: str):
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’é«˜é€ŸéŸ³å£°ã§å†ç”Ÿã™ã‚‹
        
        Args:
            text: å†ç”Ÿã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            # ä¸¦åˆ—å‡¦ç†ã§éŸ³å£°åˆæˆ
            future = self.executor.submit(
                self.text_to_speech.speak_text, text
            )
            # éåŒæœŸã§å®Ÿè¡Œï¼ˆãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
            
        except Exception as e:
            self.logger.error(f"é«˜é€ŸéŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
            if self.on_error:
                self.on_error(e)
    
    def get_performance_stats(self) -> dict:
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’å–å¾—ã™ã‚‹
        
        Returns:
            ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã®è¾æ›¸
        """
        return self.performance_stats.copy()
    
    def reset_conversation(self):
        """ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹"""
        self.ai_chat.reset_conversation()
        self.logger.info("ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
    
    def set_system_prompt(self, prompt: str):
        """
        ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´ã™ã‚‹
        
        Args:
            prompt: æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        self.ai_chat.set_system_prompt(prompt)
        self.logger.info("ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´ã—ã¾ã—ãŸ")
    
    def set_tts_voice(self, voice: str):
        """
        TTSéŸ³å£°ã‚’å¤‰æ›´ã™ã‚‹
        
        Args:
            voice: æ–°ã—ã„éŸ³å£°ã®ç¨®é¡
        """
        self.text_to_speech.set_voice(voice)
        self.logger.info(f"TTSéŸ³å£°ã‚’å¤‰æ›´ã—ã¾ã—ãŸ: {voice}")


def main():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    parser = argparse.ArgumentParser(description='é«˜é€ŸéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--auto', action='store_true', help='è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--audio-file', help='å‡¦ç†ã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--voice', default='alloy', help='TTSéŸ³å£°ã®ç¨®é¡')
    
    args = parser.parse_args()
    
    try:
        # é«˜é€ŸéŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆ
        conversation = FastVoiceConversation(tts_voice=args.voice)
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’è¨­å®š
        def on_user_speech(text):
            print(f"ğŸ¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {text}")
        
        def on_ai_response(text):
            print(f"ğŸ¤– AI: {text}")
        
        def on_error(error):
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {error}")
        
        conversation.on_user_speech = on_user_speech
        conversation.on_ai_response = on_ai_response
        conversation.on_error = on_error
        
        if args.audio_file:
            # å˜ç™ºã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
            print(f"é«˜é€ŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­: {args.audio_file}")
            response = conversation.process_audio_file_fast(args.audio_file)
            print(f"AIå¿œç­”: {response}")
            conversation.speak_response_fast(response)
        
        elif args.auto:
            # è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
            print("é«˜é€Ÿè‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚Ctrl+Cã§çµ‚äº†...")
            conversation.start_conversation(auto_mode=True)
            
            try:
                while True:
                    time.sleep(1)
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã‚’è¡¨ç¤º
                    stats = conversation.get_performance_stats()
                    if stats['total_requests'] > 0:
                        print(f"å¹³å‡å¿œç­”æ™‚é–“: {stats['avg_response_time']:.2f}ç§’")
            except KeyboardInterrupt:
                conversation.stop_conversation()
        
        else:
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  --auto: é«˜é€Ÿè‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰")
            print("  --audio-file <path>: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é«˜é€Ÿå‡¦ç†")
    
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
