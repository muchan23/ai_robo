#!/usr/bin/env python3
"""
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ 
Whisper.cppï¼ˆãƒ­ãƒ¼ã‚«ãƒ«éŸ³å£°èªè­˜ï¼‰+ OpenAIï¼ˆChatGPT + TTSï¼‰
"""

import os
import logging
import time
import threading
from typing import Optional, Callable
from pathlib import Path

from whisper_cpp_stt import WhisperCppSTT
from ai_chat import AIChat
from text_to_speech import TextToSpeech
from audio_recorder import AudioRecorder
from config import get_config


class HybridVoiceConversation:
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 api_key: Optional[str] = None,
                 chat_model: str = "gpt-4o-mini",
                 tts_voice: str = "alloy",
                 tts_model: str = "tts-1",
                 whisper_model_size: str = "small",
                 whisper_model_path: Optional[str] = None,
                 system_prompt: Optional[str] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key: OpenAI APIã‚­ãƒ¼
            chat_model: ChatGPTãƒ¢ãƒ‡ãƒ«
            tts_voice: TTSéŸ³å£°ã®ç¨®é¡
            tts_model: TTSãƒ¢ãƒ‡ãƒ«
            whisper_model_size: Whisper.cppãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
            whisper_model_path: Whisper.cppãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
            system_prompt: AIã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.logger = logging.getLogger(__name__)
        
        # å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
        self.logger.info("Whisper.cppéŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
        self.whisper_stt = WhisperCppSTT(
            model_path=whisper_model_path,
            model_size=whisper_model_size
        )
        
        self.logger.info("ChatGPTå¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
        self.ai_chat = AIChat(
            api_key=self.api_key,
            model=chat_model,
            system_prompt=system_prompt
        )
        
        self.logger.info("TTSéŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
        self.text_to_speech = TextToSpeech(
            api_key=self.api_key,
            voice=tts_voice,
            model=tts_model
        )
        
        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        config = get_config()
        self.audio_recorder = AudioRecorder(
            sample_rate=config.sample_rate,
            chunk_size=config.chunk_size
        )
        
        # çŠ¶æ…‹ç®¡ç†
        self.is_running = False
        self.conversation_thread = None
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        self.on_user_speech: Optional[Callable[[str], None]] = None
        self.on_ai_response: Optional[Callable[[str], None]] = None
        self.on_error: Optional[Callable[[Exception], None]] = None
        
        self.logger.info("ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
    
    def start_conversation(self, 
                          auto_mode: bool = True,
                          max_duration: float = 30.0,
                          silence_threshold: float = 0.01,
                          silence_duration: float = 2.0):
        """
        éŸ³å£°ä¼šè©±ã‚’é–‹å§‹ã™ã‚‹
        
        Args:
            auto_mode: è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹
            max_duration: æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
            silence_threshold: ç„¡éŸ³åˆ¤å®šã®é–¾å€¤
            silence_duration: ç„¡éŸ³ç¶™ç¶šæ™‚é–“ï¼ˆç§’ï¼‰
        """
        if self.is_running:
            self.logger.warning("æ—¢ã«ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ãŒå‹•ä½œä¸­ã§ã™")
            return
        
        self.is_running = True
        
        if auto_mode:
            # è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
            self.logger.info("è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã§ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™")
            self.audio_recorder.start_continuous_recording(
                output_dir="recordings",
                max_duration=max_duration,
                silence_threshold=silence_threshold,
                silence_duration=silence_duration,
                callback=self._process_audio_file
            )
        else:
            # æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã§å¾…æ©Ÿï¼‰
            self.conversation_thread = threading.Thread(
                target=self._manual_conversation_loop
            )
            self.conversation_thread.start()
            self.logger.info("æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã§ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™")
    
    def stop_conversation(self):
        """éŸ³å£°ä¼šè©±ã‚’åœæ­¢ã™ã‚‹"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        # éŒ²éŸ³ã‚’åœæ­¢
        self.audio_recorder.stop_continuous_recording()
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿ
        if self.conversation_thread:
            self.conversation_thread.join()
        
        self.logger.info("ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    
    def _process_audio_file(self, audio_file_path: str):
        """
        éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹
        
        Args:
            audio_file_path: éŒ²éŸ³ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        try:
            self.logger.info(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­: {audio_file_path}")
            
            # Whisper.cppã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ»é«˜é€Ÿï¼‰
            user_text = self.whisper_stt.transcribe_audio_file(
                audio_file_path=audio_file_path
            )
            
            if not user_text.strip():
                self.logger.info("éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return
            
            self.logger.info(f"èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {user_text}")
            
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            if self.on_user_speech:
                self.on_user_speech(user_text)
            
            # ChatGPT APIã§AIå¿œç­”ã‚’ç”Ÿæˆï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ»é«˜å“è³ªï¼‰
            ai_response = self.ai_chat.chat(user_text)
            
            self.logger.info(f"AIå¿œç­”: {ai_response}")
            
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
            if self.on_ai_response:
                self.on_ai_response(ai_response)
            
            # OpenAI TTS APIã§éŸ³å£°åˆæˆãƒ»å†ç”Ÿï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ»é«˜å“è³ªï¼‰
            self.text_to_speech.speak_text(ai_response)
            
            # éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ï¼‰
            try:
                Path(audio_file_path).unlink()
                self.logger.debug(f"éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {audio_file_path}")
            except Exception as e:
                self.logger.warning(f"éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {e}")
            
        except Exception as e:
            self.logger.error(f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            if self.on_error:
                self.on_error(e)
    
    def _manual_conversation_loop(self):
        """æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã®ä¼šè©±ãƒ«ãƒ¼ãƒ—"""
        self.logger.info("æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        while self.is_running:
            try:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å¾…æ©Ÿï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªå…¥åŠ›æ–¹æ³•ã‚’ä½¿ç”¨ï¼‰
                time.sleep(1)  # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                
                # ã“ã“ã§å®Ÿéš›ã®å…¥åŠ›å‡¦ç†ã‚’å®Ÿè£…
                # ä¾‹: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å…¥åŠ›ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ¤œå‡ºãªã©
                
            except Exception as e:
                self.logger.error(f"æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                if self.on_error:
                    self.on_error(e)
                break
    
    def process_audio_file(self, audio_file_path: str) -> str:
        """
        æŒ‡å®šã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦AIå¿œç­”ã‚’è¿”ã™
        
        Args:
            audio_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            AIå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            # Whisper.cppã§éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—
            user_text = self.whisper_stt.transcribe_audio_file(audio_file_path)
            
            if not user_text.strip():
                return "éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            # ChatGPT APIã§AIå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = self.ai_chat.chat(user_text)
            
            return ai_response
            
        except Exception as e:
            self.logger.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    
    def speak_response(self, text: str):
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã§å†ç”Ÿã™ã‚‹
        
        Args:
            text: å†ç”Ÿã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            self.text_to_speech.speak_text(text)
        except Exception as e:
            self.logger.error(f"éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
            if self.on_error:
                self.on_error(e)
    
    def reset_conversation(self):
        """ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹"""
        self.ai_chat.reset_conversation()
        self.logger.info("ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
    
    def set_system_prompt(self, prompt: str):
        """
        ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´ã™ã‚‹
        
        Args:
            prompt: æ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        self.ai_chat.set_system_prompt(prompt)
        self.logger.info("ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰æ›´ã—ã¾ã—ãŸ")
    
    def set_tts_voice(self, voice: str):
        """
        TTSéŸ³å£°ã‚’å¤‰æ›´ã™ã‚‹
        
        Args:
            voice: æ–°ã—ã„éŸ³å£°ã®ç¨®é¡
        """
        self.text_to_speech.set_voice(voice)
        self.logger.info(f"TTSéŸ³å£°ã‚’å¤‰æ›´ã—ã¾ã—ãŸ: {voice}")
    
    def get_system_info(self) -> dict:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—"""
        return {
            'whisper_cpp': self.whisper_stt.get_model_info(),
            'chat_model': self.ai_chat.model,
            'tts_voice': self.text_to_speech.voice,
            'tts_model': self.text_to_speech.model
        }


def main():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    parser = argparse.ArgumentParser(description='ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--auto', action='store_true', help='è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--audio-file', help='å‡¦ç†ã™ã‚‹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--voice', default='alloy', help='TTSéŸ³å£°ã®ç¨®é¡')
    parser.add_argument('--model', default='gpt-4o-mini', help='ChatGPTãƒ¢ãƒ‡ãƒ«')
    parser.add_argument('--whisper-model', default='small', help='Whisper.cppãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º')
    
    args = parser.parse_args()
    
    try:
        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰éŸ³å£°ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆ
        conversation = HybridVoiceConversation(
            chat_model=args.model,
            tts_voice=args.voice,
            whisper_model_size=args.whisper_model
        )
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’è¨­å®š
        def on_user_speech(text):
            print(f"ğŸ¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {text}")
        
        def on_ai_response(text):
            print(f"ğŸ¤– AI: {text}")
        
        def on_error(error):
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {error}")
        
        conversation.on_user_speech = on_user_speech
        conversation.on_ai_response = on_ai_response
        conversation.on_error = on_error
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¡¨ç¤º
        info = conversation.get_system_info()
        print("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:")
        print(f"  Whisper.cpp: {info['whisper_cpp']['model_size']} ({info['whisper_cpp']['model_path']})")
        print(f"  ChatGPT: {info['chat_model']}")
        print(f"  TTS: {info['tts_voice']} ({info['tts_model']})")
        print()
        
        if args.audio_file:
            # å˜ç™ºã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
            print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­: {args.audio_file}")
            response = conversation.process_audio_file(args.audio_file)
            print(f"AIå¿œç­”: {response}")
            conversation.speak_response(response)
        
        elif args.auto:
            # è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰
            print("ğŸš€ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚Ctrl+Cã§çµ‚äº†...")
            conversation.start_conversation(auto_mode=True)
            
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                conversation.stop_conversation()
        
        else:
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  --auto: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è‡ªå‹•éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰")
            print("  --audio-file <path>: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
            print("  --whisper-model <size>: Whisper.cppãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º (tiny, base, small, medium, large)")
    
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
