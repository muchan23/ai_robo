#!/usr/bin/env python3
"""
éŸ³å£°åˆ¶å¾¡ãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ 
éŸ³å£°èªè­˜ + AIè§£é‡ˆ + ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ¶å¾¡ã®çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
"""

import sys
import os
import time
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.audio.voice_recognition import VoiceRecognition
from src.ai.motor_ai_chat import MotorAIChat
from src.motor.motor_controller import MotorController

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ¤– éŸ³å£°åˆ¶å¾¡ãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)
    
    try:
        # å„ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        print("ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
        
        # éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ 
        voice_recognition = VoiceRecognition()
        print("âœ… éŸ³å£°èªè­˜ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
        # ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ¶å¾¡AI
        motor_ai = MotorAIChat()
        print("âœ… ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ¶å¾¡AIåˆæœŸåŒ–å®Œäº†")
        
        # ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ 
        motor_controller = MotorController()
        print("âœ… ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        
        print("\nğŸ¯ éŸ³å£°åˆ¶å¾¡ãƒ­ãƒœãƒƒãƒˆã‚’é–‹å§‹ã—ã¾ã™")
        print("ğŸ’¡ éŸ³å£°ã§æŒ‡ç¤ºã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šå‰ã«é€²ã‚“ã§ã€å³ã«å›ã£ã¦ã€æ­¢ã¾ã£ã¦ï¼‰")
        print("â¹ï¸  Ctrl+C ã§çµ‚äº†")
        
        while True:
            try:
                # éŸ³å£°ã‚’å¾…æ©Ÿï¼ˆéŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿï¼‰
                print("\nğŸ¤ éŸ³å£°ã‚’å¾…æ©Ÿä¸­...")
                audio_data = voice_recognition.wait_for_speech()
                
                if audio_data:
                    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                    print("ğŸ“ æ–‡å­—èµ·ã“ã—ä¸­...")
                    transcribed_text = voice_recognition.transcribe_audio(audio_data)
                    
                    if transcribed_text:
                        print(f"ğŸ“ èªè­˜çµæœ: {transcribed_text}")
                        
                        # AIè§£é‡ˆå®Ÿè¡Œ
                        print("ğŸ¤– AIè§£é‡ˆä¸­...")
                        command = motor_ai.interpret_command(transcribed_text)
                        print(f"ğŸ¤– è§£é‡ˆçµæœ: {command['message']}")
                        
                        # ã‚³ãƒãƒ³ãƒ‰ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼
                        if motor_ai.validate_command(command):
                            # ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ¶å¾¡å®Ÿè¡Œ
                            print("ğŸš— ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ¶å¾¡å®Ÿè¡Œä¸­...")
                            motor_controller.execute_command(command)
                            print("âœ… ãƒ¢ãƒ¼ã‚¿ãƒ¼åˆ¶å¾¡å®Œäº†")
                        else:
                            print("âŒ ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã§ã™")
                            voice_recognition.play_sound("error")
                        
                    else:
                        print("âŒ éŸ³å£°ãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                        voice_recognition.play_sound("error")
                else:
                    print("âŒ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                    voice_recognition.play_sound("error")
                    
            except KeyboardInterrupt:
                print("\nğŸ›‘ çµ‚äº†ã—ã¾ã™...")
                break
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                voice_recognition.play_sound("error")
                continue
        
    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return 1
    finally:
        # ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if 'voice_recognition' in locals():
            voice_recognition.cleanup()
        if 'motor_controller' in locals():
            motor_controller.cleanup()
    
    return 0


if __name__ == "__main__":
    exit(main())
